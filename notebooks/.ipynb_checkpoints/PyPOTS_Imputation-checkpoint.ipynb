{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“‘ Tutorials for PyPOTS Imputation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“€ Preparing the **PhysioNet-2012** dataset for this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 21:33:28 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2025-02-25 21:33:28 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2025-02-25 21:33:28 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2025-02-25 21:33:28 [INFO]: Loaded successfully!\n",
      "2025-02-25 21:33:41 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2025-02-25 21:33:41 [INFO]: 69068 values masked out in the val set as ground truth, take 9.95% of the original observed values\n",
      "2025-02-25 21:33:41 [INFO]: 86352 values masked out in the test set as ground truth, take 9.97% of the original observed values\n",
      "2025-02-25 21:33:41 [INFO]: Total sample number: 11988\n",
      "2025-02-25 21:33:41 [INFO]: Training set size: 7671 (63.99%)\n",
      "2025-02-25 21:33:41 [INFO]: Validation set size: 1918 (16.00%)\n",
      "2025-02-25 21:33:41 [INFO]: Test set size: 2399 (20.01%)\n",
      "2025-02-25 21:33:41 [INFO]: Number of steps: 48\n",
      "2025-02-25 21:33:41 [INFO]: Number of features: 37\n",
      "2025-02-25 21:33:41 [INFO]: Train set missing rate: 79.74%\n",
      "2025-02-25 21:33:41 [INFO]: Validating set missing rate: 81.65%\n",
      "2025-02-25 21:33:41 [INFO]: Test set missing rate: 81.70%\n"
     ]
    }
   ],
   "source": [
    "from benchpots.datasets import preprocess_physionet2012\n",
    "\n",
    "# Load the dataset with artificially missing values\n",
    "physionet2012_dataset = preprocess_physionet2012(subset=\"all\", rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the datasets for training, validating, and testing.\n",
    "\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "}\n",
    "\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"X_ori\": physionet2012_dataset['val_X_ori'],\n",
    "}\n",
    "\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[            nan,             nan,             nan, ...,\n",
       "                     nan, -3.34186687e+00,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        ...,\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan]],\n",
       "\n",
       "       [[            nan,             nan,             nan, ...,\n",
       "                     nan, -2.82949840e-01,  2.50627088e-03],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "         -4.98983937e-01,             nan,  8.54514434e-04],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        ...,\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan, -6.04831464e-02, -1.07077807e-02],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan, -6.04831464e-02,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan, -6.04831464e-02,             nan]],\n",
       "\n",
       "       [[-9.61992367e-02, -2.95986376e-01, -3.01610806e-01, ...,\n",
       "         -1.31637473e-01,  5.86954393e-02,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  5.86954393e-02,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  5.86954393e-02,             nan],\n",
       "        ...,\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  5.86954393e-02,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  5.86954393e-02,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  5.86954393e-02,             nan]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[            nan,             nan,             nan, ...,\n",
       "                     nan,  4.96090793e+00,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        ...,\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan]],\n",
       "\n",
       "       [[            nan,             nan,             nan, ...,\n",
       "                     nan,  7.45859174e-02, -7.97242014e-04],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "         -6.69217664e-01,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        ...,\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  3.92395479e-01,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,  3.92395479e-01,             nan]],\n",
       "\n",
       "       [[            nan,             nan,             nan, ...,\n",
       "                     nan, -3.98155806e-01, -2.88771016e-02],\n",
       "        [-3.17370638e-01, -2.85824081e-01, -2.87708698e-01, ...,\n",
       "          5.85136114e-01,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        ...,\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan],\n",
       "        [            nan,             nan,             nan, ...,\n",
       "                     nan,             nan,             nan]]],\n",
       "      shape=(7671, 48, 37))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_for_training['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physionet2012_dataset['n_steps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physionet2012_dataset['n_features']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ An example of **SAITS** for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 21:40:45 [INFO]: No given device, using default device: cpu\n",
      "2025-02-25 21:40:45 [INFO]: Model files will be saved to tutorial_results/imputation/saits/20250225_T214045\n",
      "2025-02-25 21:40:45 [INFO]: Tensorboard file will be saved to tutorial_results/imputation/saits/20250225_T214045/tensorboard\n",
      "2025-02-25 21:40:45 [INFO]: SAITS initialized with the given hyperparameters, the number of trainable parameters: 1,378,358\n"
     ]
    }
   ],
   "source": [
    "from pypots.optim import Adam\n",
    "from pypots.imputation import SAITS\n",
    "\n",
    "# initialize the model\n",
    "saits = SAITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_layers=2,\n",
    "    d_model=256,\n",
    "    d_ffn=128,\n",
    "    n_heads=4,\n",
    "    d_k=64,\n",
    "    d_v=64,\n",
    "    dropout=0.1,\n",
    "    attn_dropout=0.1,\n",
    "    ##### Esto diferencia al SAIT del modelo Transformer\n",
    "    diagonal_attention_mask=True,  # otherwise the original self-attention mechanism will be applied\n",
    "    ORT_weight=1,  # you can adjust the weight values of arguments ORT_weight\n",
    "    # and MIT_weight to make the SAITS model focus more on one task. Usually you can just leave them to the default values, i.e. 1.\n",
    "    MIT_weight=1,\n",
    "    batch_size=32,\n",
    "    # here we set epochs=10 for a quick demo, you can set it to 100 or more for better performance\n",
    "    epochs=10,\n",
    "    # here we set patience=3 to early stop the training if the evaluting loss doesn't decrease for 3 epoches.\n",
    "    # You can leave it to defualt as None to disable early stopping.\n",
    "    patience=3,\n",
    "    # give the optimizer. Different from torch.optim.Optimizer, you don't have to specify model's parameters when\n",
    "    # initializing pypots.optim.Optimizer. You can also leave it to default. It will initilize an Adam optimizer with lr=0.001.\n",
    "    optimizer=Adam(lr=1e-3),\n",
    "    # this num_workers argument is for torch.utils.data.Dataloader. It's the number of subprocesses to use for data loading.\n",
    "    # Leaving it to default as 0 means data loading will be in the main process, i.e. there won't be subprocesses.\n",
    "    # You can increase it to >1 if you think your dataloading is a bottleneck to your model training speed\n",
    "    num_workers=0,\n",
    "    # just leave it to default as None, PyPOTS will automatically assign the best device for you.\n",
    "    # Set it as 'cpu' if you don't have CUDA devices. You can also set it to 'cuda:0' or 'cuda:1' if you have multiple CUDA devices, even parallelly on ['cuda:0', 'cuda:1']\n",
    "    device=None,  \n",
    "    # set the path for saving tensorboard and trained model files \n",
    "    saving_path=\"tutorial_results/imputation/saits\",\n",
    "    # only save the best model after training finished.\n",
    "    # You can also set it as \"better\" to save models performing better ever during training.\n",
    "    model_saving_strategy=\"best\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-25 21:41:49 [INFO]: Epoch 001 - training loss: 0.7339, validation loss: 0.4262\n",
      "2025-02-25 21:42:39 [INFO]: Epoch 002 - training loss: 0.5421, validation loss: 0.4099\n",
      "2025-02-25 21:43:31 [INFO]: Epoch 003 - training loss: 0.4953, validation loss: 0.3733\n",
      "2025-02-25 21:44:07 [INFO]: Epoch 004 - training loss: 0.4601, validation loss: 0.3560\n",
      "2025-02-25 21:44:42 [INFO]: Epoch 005 - training loss: 0.4384, validation loss: 0.3392\n",
      "2025-02-25 21:45:18 [INFO]: Epoch 006 - training loss: 0.4151, validation loss: 0.3304\n",
      "2025-02-25 21:45:55 [INFO]: Epoch 007 - training loss: 0.3985, validation loss: 0.3278\n",
      "2025-02-25 21:46:30 [INFO]: Epoch 008 - training loss: 0.3877, validation loss: 0.3241\n",
      "2025-02-25 21:47:06 [INFO]: Epoch 009 - training loss: 0.3812, validation loss: 0.3189\n",
      "2025-02-25 21:47:42 [INFO]: Epoch 010 - training loss: 0.3724, validation loss: 0.3167\n",
      "2025-02-25 21:47:42 [INFO]: Finished training. The best model is from epoch#10.\n",
      "2025-02-25 21:47:42 [INFO]: Saved the model to tutorial_results/imputation/saits/20250225_T214045/SAITS.pypots\n"
     ]
    }
   ],
   "source": [
    "# train the model on the training set, and validate it on the validating set to select the best model for testing in the next step\n",
    "saits.fit(train_set=dataset_for_training, val_set=dataset_for_validating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the testing stage, impute the originally-missing values and artificially-missing values in the test set\n",
    "\n",
    "saits_results = saits.predict(dataset_for_testing)\n",
    "saits_imputation = saits_results[\"imputation\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-5.4385591e-01, -3.9818963e-01, -3.1251264e-01, ...,\n",
       "         -3.4369278e-01, -1.0496655e+00,  2.6155731e-03],\n",
       "        [ 2.2478100e-02, -2.2300261e-01, -1.4868762e-01, ...,\n",
       "         -7.8569335e-01, -1.0496655e+00,  2.2831559e-03],\n",
       "        [-5.4463887e-01, -3.4745437e-01, -2.9453677e-01, ...,\n",
       "         -3.1145626e-01, -1.0496655e+00, -2.5334309e-03],\n",
       "        ...,\n",
       "        [-5.2853882e-01, -3.4087366e-01, -3.1559777e-01, ...,\n",
       "         -3.2069087e-01, -1.0496655e+00,  2.4970931e-03],\n",
       "        [-4.8634955e-01, -3.2567972e-01, -2.9759574e-01, ...,\n",
       "         -2.9512572e-01, -1.0496655e+00,  2.4509071e-03],\n",
       "        [-5.6467801e-01, -3.3407164e-01, -3.4903508e-01, ...,\n",
       "         -3.0918378e-01, -1.0496655e+00,  2.5065220e-03]],\n",
       "\n",
       "       [[-4.0907586e-01, -2.6457563e-01, -2.5503874e-01, ...,\n",
       "          2.8050733e-01, -1.3758801e+00, -5.7525113e-03],\n",
       "        [-4.0177315e-01, -4.5280036e-01, -3.8542396e-01, ...,\n",
       "          3.6182575e-02, -1.3793929e+00, -1.8499468e-02],\n",
       "        [-5.1438874e-01, -4.2749870e-01, -3.7789428e-01, ...,\n",
       "          7.0607513e-02, -1.3484373e+00, -1.1629868e-02],\n",
       "        ...,\n",
       "        [-5.3832805e-01, -3.9208347e-01, -2.9667023e-01, ...,\n",
       "         -1.2813330e-01, -1.1804113e+00, -8.6336210e-03],\n",
       "        [-4.0181574e-01, -2.5204831e-01, -1.6359460e-01, ...,\n",
       "         -1.7727238e-01, -1.3793929e+00, -6.2434352e-03],\n",
       "        [-4.8545590e-01, -2.6249132e-01, -2.0810580e-01, ...,\n",
       "         -1.7926592e-01, -1.2137047e+00, -1.0707781e-02]],\n",
       "\n",
       "       [[-3.8696158e-01, -3.0762613e-01, -2.5197029e-01, ...,\n",
       "         -2.3352277e-01, -6.7623919e-01, -7.4042678e-03],\n",
       "        [-4.3973398e-01, -2.3496038e-01, -2.7990213e-01, ...,\n",
       "         -3.5562921e-01, -6.7623919e-01, -4.1007549e-03],\n",
       "        [-5.0170040e-01, -3.3862272e-01, -2.9422924e-01, ...,\n",
       "         -3.6320612e-02, -6.7623919e-01, -6.5379278e-03],\n",
       "        ...,\n",
       "        [-3.3810055e-01, -3.4715930e-01, -3.2600462e-01, ...,\n",
       "         -1.3318503e-01, -5.3322488e-01, -6.8598394e-03],\n",
       "        [-4.6261847e-01, -3.4281442e-01, -3.6755764e-01, ...,\n",
       "         -1.7804438e-01, -5.3322488e-01, -2.9680636e-03],\n",
       "        [-5.6109953e-01, -4.0973544e-01, -4.0996373e-01, ...,\n",
       "         -1.8271080e-01, -5.3322488e-01,  1.2893688e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.5142321e-01, -3.5010535e-01, -2.6966581e-01, ...,\n",
       "         -4.7210494e-01, -1.3356940e+00,  1.3408421e-02],\n",
       "        [-5.7151753e-01, -4.2252159e-01, -3.8366508e-01, ...,\n",
       "         -2.0821071e-01, -1.3988520e+00, -1.1122730e-03],\n",
       "        [-5.5064321e-01, -4.3003437e-01, -3.8300315e-01, ...,\n",
       "         -1.2636010e-01, -1.3356940e+00, -4.1896543e-03],\n",
       "        ...,\n",
       "        [-4.2077783e-01, -4.0431720e-01, -3.4613580e-01, ...,\n",
       "         -2.3498869e-01, -1.3356940e+00,  1.9045261e-03],\n",
       "        [-5.0212985e-01, -3.8787553e-01, -3.5629532e-01, ...,\n",
       "         -2.3734042e-01, -1.3796867e+00,  5.4642772e-03],\n",
       "        [-3.8342780e-01, -3.7410146e-01, -3.3326015e-01, ...,\n",
       "         -1.9932340e-01, -1.3356940e+00,  4.0529361e-03]],\n",
       "\n",
       "       [[-6.1825496e-01, -3.3069640e-01, -3.3063686e-01, ...,\n",
       "         -9.2008841e-01, -6.0075939e-01, -1.4312647e-02],\n",
       "        [-6.1067307e-01, -2.8002998e-01, -3.9689198e-01, ...,\n",
       "         -1.2800211e-01, -3.0543911e-01, -3.3832371e-02],\n",
       "        [-5.2993631e-01, -2.1781941e-01, -2.5619647e-01, ...,\n",
       "         -8.2153207e-01, -2.3146267e-01, -2.0571370e-02],\n",
       "        ...,\n",
       "        [-4.1850644e-01, -2.2340581e-01, -2.7811980e-01, ...,\n",
       "         -1.1760749e-01, -1.2355815e-01, -1.1753981e-03],\n",
       "        [-3.9531949e-01, -1.5298165e-01, -2.3300970e-01, ...,\n",
       "         -1.3253562e-01, -1.3208717e-01,  5.7430752e-04],\n",
       "        [-3.1664243e-01, -1.7915736e-01, -2.2252938e-01, ...,\n",
       "         -1.2425636e-01, -1.2941469e-01,  1.2463168e-03]],\n",
       "\n",
       "       [[-2.2130992e-01, -2.3410203e-01, -7.8916773e-02, ...,\n",
       "          1.2929500e+00,  1.7828124e+00, -2.2713702e-02],\n",
       "        [-5.0832158e-01, -3.0943304e-01, -3.4826261e-01, ...,\n",
       "         -1.1080934e-01,  1.7828124e+00, -8.5912114e-03],\n",
       "        [-4.0666553e-01, -3.9391717e-01, -3.4732193e-01, ...,\n",
       "         -8.4597319e-02,  1.7828124e+00, -7.5794430e-03],\n",
       "        ...,\n",
       "        [-2.9671147e-01, -3.9179009e-01, -2.7501220e-01, ...,\n",
       "         -2.2549331e-01,  1.8066480e+00, -2.5232533e-02],\n",
       "        [-4.2042428e-01, -3.7960190e-01, -3.2857206e-01, ...,\n",
       "         -2.4635443e-01,  1.8066480e+00, -1.0872075e-02],\n",
       "        [-4.0039241e-01, -4.1320038e-01, -3.2071254e-01, ...,\n",
       "         -1.7236698e-01,  1.8066480e+00, -1.2319675e-02]]],\n",
       "      shape=(2399, 48, 37), dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saits_imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.50989085, -0.36246145, -0.32518214, ..., -0.08309655,\n",
       "        -0.31181836, -0.01096718],\n",
       "       [-0.52665305, -0.32788512, -0.31562158, ..., -0.07947987,\n",
       "        -0.09837142, -0.0109406 ],\n",
       "       [-0.51331156, -0.3152645 , -0.3123883 , ..., -0.07330464,\n",
       "        -0.09311794, -0.01073911],\n",
       "       ...,\n",
       "       [-0.43129858, -0.34363335, -0.30473357, ..., -0.20775025,\n",
       "        -0.0294342 , -0.00497112],\n",
       "       [-0.45912376, -0.33366537, -0.32008284, ..., -0.20705797,\n",
       "        -0.02986197, -0.00422864],\n",
       "       [-0.4829212 , -0.33076856, -0.3313236 , ..., -0.19852372,\n",
       "        -0.03277353, -0.00243696]], shape=(48, 37), dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(saits_imputation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2399, 48, 37)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saits_imputation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de NaNs en test_X_ori despuÃ©s de imputaciÃ³n (con 0): 0\n",
      "Testing mean absolute error (MAE): 0.3040\n"
     ]
    }
   ],
   "source": [
    "from pypots.utils.metrics import calc_mae\n",
    "\n",
    "physionet2012_dataset['test_X_indicating_mask'] = np.isnan(physionet2012_dataset['test_X']).astype(int)\n",
    "\n",
    "# Crear una copia de los datos originales\n",
    "test_X_ori_fixed = np.copy(physionet2012_dataset['test_X_ori'])\n",
    "\n",
    "# Reemplazar NaNs por 0 (valor constante)\n",
    "test_X_ori_fixed[np.isnan(test_X_ori_fixed)] = 0\n",
    "\n",
    "# Verificar si quedan NaNs\n",
    "num_nans_fixed = np.isnan(test_X_ori_fixed).sum()\n",
    "print(f\"NÃºmero de NaNs en test_X_ori despuÃ©s de imputaciÃ³n (con 0): {num_nans_fixed}\")\n",
    "\n",
    "# calculate mean absolute error on the ground truth (artificially-missing values)\n",
    "# predictions, targets, masks\n",
    "testing_mae = calc_mae(\n",
    "    saits_imputation, \n",
    "    test_X_ori_fixed, \n",
    "    physionet2012_dataset['test_X_indicating_mask'],\n",
    ")\n",
    "print(f\"Testing mean absolute error (MAE): {testing_mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
